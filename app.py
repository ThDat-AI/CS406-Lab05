import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import config

# --- C·∫•u h√¨nh trang ---
st.set_page_config(
    page_title="Face Mask Detection",
    page_icon="üò∑",
    layout="centered"
)

# --- CSS t√πy ch·ªânh ---
st.markdown("""
    <style>
    .stApp { background-color: #f0f2f6; }
    h1 { color: #333; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# --- Load Model ---
@st.cache_resource
def load_model(model_path):
    try:
        return YOLO(model_path)
    except Exception as e:
        st.error(f"L·ªói t·∫£i model: {e}")
        return None

# --- H√†m v·∫Ω Bounding Box ---
def plot_boxes(image_source, results, conf_threshold):
    # N·∫øu image_source l√† PIL Image th√¨ chuy·ªÉn sang numpy array
    if isinstance(image_source, Image.Image):
        img_array = np.array(image_source)
    else:
        img_array = image_source.copy() # N·∫øu l√† numpy array (t·ª´ cv2)

    for result in results:
        boxes = result.boxes
        for box in boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])
            cls_id = int(box.cls[0])

            if conf >= conf_threshold:
                color = config.COLORS.get(cls_id, (255, 255, 255))
                label = config.CLASS_NAMES.get(cls_id, "Unknown")
                text = f"{label}: {conf:.2f}"

                cv2.rectangle(img_array, (x1, y1), (x2, y2), color, 2)
                (w, h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
                cv2.rectangle(img_array, (x1, y1 - 20), (x1 + w, y1), color, -1)
                cv2.putText(img_array, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)

    return img_array

# --- Main App ---
def main():
    st.title("üò∑ Face Mask Detection Demo")
    
    # Sidebar
    st.sidebar.header("C·∫•u h√¨nh")
    mode = st.sidebar.radio("Ch·ªçn ch·∫ø ƒë·ªô:", ["Upload ·∫¢nh", "Ch·ª•p ·∫¢nh (Snapshot)", "Real-time Webcam"])
    conf_threshold = st.sidebar.slider("ƒê·ªô tin c·∫≠y (Threshold)", 0.0, 1.0, config.CONFIDENCE_THRESHOLD, 0.05)

    model = load_model(config.MODEL_PATH)

    if not model:
        st.warning(f"Ch∆∞a t√¨m th·∫•y model t·∫°i {config.MODEL_PATH}")
        return

    # --- CH·∫æ ƒê·ªò 1: UPLOAD ·∫¢NH ---
    if mode == "Upload ·∫¢nh":
        uploaded_file = st.file_uploader("T·∫£i l√™n ·∫£nh...", type=['jpg', 'jpeg', 'png'])
        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
            if st.button("Ph√°t hi·ªán"):
                results = model(image, conf=0.15, agnostic_nms=True)
                res_img = plot_boxes(image, results, conf_threshold)
                st.image(res_img, caption="K·∫øt qu·∫£", use_container_width=True)

    # --- CH·∫æ ƒê·ªò 2: CH·ª§P ·∫¢NH (SNAPSHOT) ---
    elif mode == "Ch·ª•p ·∫¢nh (Snapshot)":
        camera_image = st.camera_input("Ch·ª•p ·∫£nh t·ª´ webcam")
        if camera_image:
            image = Image.open(camera_image)
            results = model(image, conf=0.15, agnostic_nms=True)
            res_img = plot_boxes(image, results, conf_threshold)
            st.image(res_img, caption="K·∫øt qu·∫£", use_container_width=True)

    # --- CH·∫æ ƒê·ªò 3: REAL-TIME WEBCAM (M·ªöI) ---
    elif mode == "Real-time Webcam":
        st.write("Nh·∫•n **Start** ƒë·ªÉ b·∫≠t camera. Nh·∫•n **Stop** ƒë·ªÉ d·ª´ng.")
        run = st.checkbox('B·∫≠t Camera')
        
        # T·∫°o m·ªôt khung h√¨nh tr·ªëng ƒë·ªÉ c·∫≠p nh·∫≠t li√™n t·ª•c
        FRAME_WINDOW = st.image([])
        
        # Kh·ªüi t·∫°o camera (ID 0 th∆∞·ªùng l√† webcam m·∫∑c ƒë·ªãnh)
        camera = cv2.VideoCapture(0)

        while run:
            ret, frame = camera.read()
            if not ret:
                st.error("Kh√¥ng th·ªÉ truy c·∫≠p webcam.")
                break
            
            # OpenCV d√πng h·ªá m√†u BGR, c·∫ßn chuy·ªÉn sang RGB ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # --- Inference (D·ª± ƒëo√°n) ---
            # Stream=True gi√∫p model x·ª≠ l√Ω nhanh h∆°n cho video
            results = model(frame, stream=True, verbose=False, conf=0.15, agnostic_nms=True)
            
            # --- V·∫Ω Box ---
            # L∆∞u √Ω: frame l√∫c n√†y l√† numpy array
            processed_frame = plot_boxes(frame, results, conf_threshold)

            # --- Hi·ªÉn th·ªã l√™n UI ---
            FRAME_WINDOW.image(processed_frame)

        # Gi·∫£i ph√≥ng camera khi t·∫Øt checkbox
        camera.release()

if __name__ == "__main__":
    main()